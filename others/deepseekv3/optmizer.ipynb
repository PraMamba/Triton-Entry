{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 非混合精度训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from TritonAdam import TritonAdamW\n",
    "import os\n",
    "os.environ['TRITON_PRINT_AUTOTUNING'] = '1'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "- 加载fp32的模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/models/Qwen2.5-0.5B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).cuda()\n",
    "iters = 100\n",
    "for p in model.parameters():\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非Fused版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1075,  0.1404, -0.0801,  ..., -0.0880, -0.0858,  0.0921],\n",
      "        [-0.1106,  0.0991,  0.0811,  ..., -0.1011,  0.1000, -0.1082],\n",
      "        [ 0.0660, -0.1091, -0.0925,  ..., -0.1007,  0.0771, -0.0990],\n",
      "        ...,\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1390, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1390, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1390, -0.1400,  0.1493]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "105.65606689453125\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), fused=False)\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "print(p) # 刷新再跑，p应该差不多\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fused版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:11<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1074,  0.1406, -0.0792,  ..., -0.0878, -0.0854,  0.0921],\n",
      "        [-0.1102,  0.0993,  0.0809,  ..., -0.1018,  0.1003, -0.1085],\n",
      "        [ 0.0656, -0.1093, -0.0923,  ..., -0.1019,  0.0770, -0.0989],\n",
      "        ...,\n",
      "        [ 0.1397, -0.1396,  0.1343,  ..., -0.1390, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1343,  ..., -0.1390, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1343,  ..., -0.1390, -0.1400,  0.1493]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "44.47935485839844\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), fused=True)\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "print(p) # 刷新再跑，p应该差不多\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triton Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全部fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_custom_init, p_dtype: torch.float32, master_p_dtype: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:12<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1075,  0.1403, -0.0811,  ..., -0.0880, -0.0860,  0.0922],\n",
      "        [-0.1108,  0.0990,  0.0814,  ..., -0.1010,  0.0998, -0.1080],\n",
      "        [ 0.0664, -0.1090, -0.0928,  ..., -0.0997,  0.0772, -0.0992],\n",
      "        ...,\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1391, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1391, -0.1400,  0.1493],\n",
      "        [ 0.1397, -0.1396,  0.1342,  ..., -0.1391, -0.1400,  0.1493]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "39.631134033203125\n"
     ]
    }
   ],
   "source": [
    "optimizer = TritonAdamW(model.parameters())\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "print(p) # 刷新再跑，p应该差不多\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1阶2阶动量为bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_custom_init, p_dtype: torch.float32, master_p_dtype: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1063,  0.1391, -0.0812,  ..., -0.0865, -0.0847,  0.0898],\n",
      "        [-0.1098,  0.0987,  0.0802,  ..., -0.1018,  0.1005, -0.1086],\n",
      "        [ 0.0653, -0.1065, -0.0904,  ..., -0.0995,  0.0778, -0.0992],\n",
      "        ...,\n",
      "        [ 0.1403, -0.1397,  0.1341,  ..., -0.1388, -0.1399,  0.1495],\n",
      "        [ 0.1403, -0.1397,  0.1341,  ..., -0.1388, -0.1399,  0.1495],\n",
      "        [ 0.1403, -0.1397,  0.1341,  ..., -0.1388, -0.1399,  0.1495]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "27.99335289001465\n"
     ]
    }
   ],
   "source": [
    "optimizer = TritonAdamW(model.parameters(), exp_avg_dtype=torch.bfloat16, exp_avg_sq_dtype=torch.bfloat16)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "print(p) # 刷新再跑，p应该差不多\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 混合精度训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from TritonAdam import TritonAdamW\n",
    "from apex.optimizers import FusedAdam as ApexFusedAdam\n",
    "from transformer_engine.pytorch.optimizers import FusedAdam as TEFusedAdam\n",
    "import os\n",
    "os.environ['TRITON_PRINT_AUTOTUNING'] = '1'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "- 加载bf16的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/models/Qwen2.5-0.5B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16).cuda()\n",
    "iters = 100\n",
    "for p in model.parameters():\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apex\n",
    "- apex只有标准的混合精度训练，fp32的master weight和1，2阶动量，bf16/fp16的model weight和grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.87024688720703\n"
     ]
    }
   ],
   "source": [
    "optimizer = ApexFusedAdam(model.parameters(), capturable=True, master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Engine\n",
    "- 最新的te，支持多种精度（可以点进去看下），比如1，2阶动量支持fp16，int8之类的，但都需要进行scale，但是不支持bf16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.55250549316406\n"
     ]
    }
   ],
   "source": [
    "optimizer = TEFusedAdam(model.parameters(), master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fp16的1，2阶动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.7933349609375\n"
     ]
    }
   ],
   "source": [
    "optimizer = TEFusedAdam(model.parameters(), \n",
    "                        exp_avg_dtype=torch.float16,\n",
    "                        exp_avg_sq_dtype=torch.float16,\n",
    "                        master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fp16的1，2阶动量 + fp32的grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.6219482421875\n"
     ]
    }
   ],
   "source": [
    "optimizer = TEFusedAdam(model.parameters(), \n",
    "                        exp_avg_dtype=torch.float16,\n",
    "                        exp_avg_sq_dtype=torch.float16,\n",
    "                        use_decoupled_grad=True,\n",
    "                        master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "\n",
    "# grad必须和param的精度是一样的，如果是bf16的p，使用fp32的g，那么就需要使用其它属性进行存储\n",
    "for p in model.parameters():\n",
    "    p.decoupled_grad = p.grad.float()\n",
    "    p.grad = None\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triton Adam\n",
    "- 基本就是对着TE中的进行写的，接口基本都差不多，无缝衔接Megatron框架\n",
    "- 目前支持master weight是fp32，model weight bf16， grad fp32 和 bf16都可以，1，2阶动量bf16或者fp32。无多余功能，基本满足训练需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_custom_init, p_dtype: torch.bfloat16, master_p_dtype: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.33610534667969\n"
     ]
    }
   ],
   "source": [
    "optimizer = TritonAdamW(model.parameters(), master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bf16的1，2阶动量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_custom_init, p_dtype: torch.bfloat16, master_p_dtype: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.398710250854492\n"
     ]
    }
   ],
   "source": [
    "optimizer = TritonAdamW(model.parameters(), \n",
    "                        exp_avg_dtype=torch.bfloat16,\n",
    "                        exp_avg_sq_dtype=torch.bfloat16,\n",
    "                        master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bf16的1，2阶动量 + fp32的grad\n",
    "- 这个就是deepseekv3中的配置\n",
    "- 在megatron中，它会使用一个fp32的grad buffer去存储梯度\n",
    "- 所有micro batch的梯度都加到这个buffer中，通过hook实现，下面是伪代码\n",
    "- grad_buffer += p.grad\n",
    "- p.grad = None\n",
    "- 当所有micro batch都计算完后\n",
    "- optimizer.model_p.decoupled_grad = grad_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_custom_init, p_dtype: torch.bfloat16, master_p_dtype: torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.23297119140625\n"
     ]
    }
   ],
   "source": [
    "optimizer = TritonAdamW(model.parameters(), \n",
    "                        exp_avg_dtype=torch.bfloat16,\n",
    "                        exp_avg_sq_dtype=torch.bfloat16,\n",
    "                        use_decoupled_grad=True,\n",
    "                        master_weights=True)\n",
    "torch.cuda.empty_cache()\n",
    "inp_ids = torch.arange(128).reshape(4,-1).cuda()\n",
    "for _ in tqdm(range(iters)):\n",
    "    out = model(inp_ids)\n",
    "    out.logits.mean().backward()\n",
    "    optimizer.step()\n",
    "    break\n",
    "\n",
    "# grad必须和param的精度是一样的，如果是bf16的p，使用fp32的g，那么就需要使用其它属性进行存储\n",
    "for p in model.parameters():\n",
    "    p.decoupled_grad = p.grad.float()\n",
    "    p.grad = None\n",
    "ms = triton.testing.do_bench(lambda: optimizer.step(), rep=1000)\n",
    "print(ms)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
